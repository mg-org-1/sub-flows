{
  "id": "91f6bbe2-ed41-4fd6-bac7-71d5b5864ecb",
  "revision": 0,
  "last_node_id": 140,
  "last_link_id": 394,
  "nodes": [
    {
      "id": 72,
      "type": "Canny",
      "pos": [
        180,
        1200
      ],
      "size": [
        240,
        90
      ],
      "flags": {},
      "order": 0,
      "mode": 4,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": []
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "Canny",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        0.1,
        0.2
      ]
    },
    {
      "id": 79,
      "type": "MarkdownNote",
      "pos": [
        1650,
        1360
      ],
      "size": [
        320,
        250
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "KSampler settings",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "You can test and find the best setting by yourself. The following table is for reference.\n\n| model            | steps | cfg |\n|---------------------|---------------|---------------|\n| fp8_e4m3fn             | 20                | 2.5               |\n| fp8_e4m3fn + 4 Steps lightning LoRA    | 4               | 1.0               |\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 68,
      "type": "Note",
      "pos": [
        -1100,
        -490
      ],
      "size": [
        310,
        90
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Increase the shift if you get too many blury/dark/bad images. Decrease if you want to try increasing detail."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 108,
      "type": "DepthAnythingV2Preprocessor",
      "pos": [
        540,
        1280
      ],
      "size": [
        279.6646423339844,
        82
      ],
      "flags": {},
      "order": 3,
      "mode": 4,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": []
        }
      ],
      "properties": {
        "cnr_id": "comfyui_controlnet_aux",
        "ver": "cc6b232f4a47f0cdf70f4e1bfa24b74bd0d75bf1",
        "Node name for S&R": "DepthAnythingV2Preprocessor",
        "ue_properties": {
          "widget_ue_connectable": {
            "ckpt_name": true,
            "resolution": true
          },
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "depth_anything_v2_vitb.pth",
        512
      ]
    },
    {
      "id": 105,
      "type": "MarkdownNote",
      "pos": [
        -1880,
        1050
      ],
      "size": [
        530,
        250
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Lotus Depth",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "**Diffusion Model**\n\nDownload [lotus-depth-d-v1-1.safetensors](https://huggingface.co/Comfy-Org/lotus/resolve/main/lotus-depth-d-v1-1.safetensors) \n and place it in **ComfyUI/models/diffusion_models**\n\n**VAE Model**\n\nDownload  [vae-ft-mse-840000-ema-pruned.safetensors](https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors)  and place it in **ComfyUI/models/vae** or you can use any SD1.5 VAE if you prefer.\n\n\n```\nComfyUI/\n‚îú‚îÄ‚îÄ models/\n‚îÇ   ‚îú‚îÄ‚îÄ diffusion_models/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ lotus-depth-d-v1-1.safetensors\n‚îÇ   ‚îî‚îÄ‚îÄ vae/\n‚îÇ       ‚îî‚îÄ‚îÄ  lvae-ft-mse-840000-ema-pruned.safetensors\n```\n\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        -1780,
        130
      ],
      "size": [
        380,
        106
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            215
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "directory": "text_encoders"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "qwen_image",
        "default"
      ]
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        -1780,
        290
      ],
      "size": [
        380,
        58
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            216
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1930,
        -130
      ],
      "size": [
        310,
        46
      ],
      "flags": {},
      "order": 35,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 128
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            110
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "VAEDecode",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 86,
      "type": "Note",
      "pos": [
        1640,
        1170
      ],
      "size": [
        307.4002380371094,
        127.38092803955078
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Set cfg to 1.0 for a speed boost at the cost of consistency. Samplers like res_multistep work pretty well at cfg 1.0\n\nThe official number of steps is 50 but I think that's too much. Even just 10 steps seems to work."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 85,
      "type": "ControlNetApplyAdvanced",
      "pos": [
        1200,
        90
      ],
      "size": [
        220,
        186
      ],
      "flags": {},
      "order": 31,
      "mode": 0,
      "inputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 151
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 152
        },
        {
          "name": "control_net",
          "type": "CONTROL_NET",
          "link": 150
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 212
        },
        {
          "name": "vae",
          "shape": 7,
          "type": "VAE",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "links": [
            154
          ]
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "links": [
            155
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "ControlNetApplyAdvanced",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        1,
        0,
        0.402
      ]
    },
    {
      "id": 73,
      "type": "PreviewImage",
      "pos": [
        1590,
        440
      ],
      "size": [
        230,
        258
      ],
      "flags": {},
      "order": 23,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 211
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "PreviewImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 84,
      "type": "ControlNetLoader",
      "pos": [
        750,
        150
      ],
      "size": [
        380,
        58
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CONTROL_NET",
          "type": "CONTROL_NET",
          "links": [
            150
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "ControlNetLoader",
        "models": [
          {
            "name": "Qwen-Image-InstantX-ControlNet-Union.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image-InstantX-ControlNets/resolve/main/split_files/controlnet/Qwen-Image-InstantX-ControlNet-Union.safetensors",
            "directory": "controlnet"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen/Qwen-Image-InstantX-ControlNet-Union.safetensors"
      ]
    },
    {
      "id": 129,
      "type": "DWPreprocessor",
      "pos": [
        860,
        320
      ],
      "size": [
        294.72265625,
        222
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 226
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            211,
            212
          ]
        },
        {
          "name": "POSE_KEYPOINT",
          "type": "POSE_KEYPOINT",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui_controlnet_aux",
        "ver": "cc6b232f4a47f0cdf70f4e1bfa24b74bd0d75bf1",
        "Node name for S&R": "DWPreprocessor",
        "ue_properties": {
          "widget_ue_connectable": {
            "detect_hand": true,
            "detect_body": true,
            "detect_face": true,
            "resolution": true,
            "bbox_detector": true,
            "pose_estimator": true,
            "scale_stick_for_xinsr_cn": true
          },
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "enable",
        "enable",
        "enable",
        512,
        "yolox_l.onnx",
        "dw-ll_ucoco_384_bs5.torchscript.pt",
        "disable"
      ]
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        1180,
        -180
      ],
      "size": [
        310,
        58
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            156
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        3.1000000000000005
      ]
    },
    {
      "id": 127,
      "type": "EmptySD3LatentImage",
      "pos": [
        900,
        -70
      ],
      "size": [
        270,
        106
      ],
      "flags": {},
      "order": 22,
      "mode": 0,
      "inputs": [
        {
          "name": "width",
          "type": "INT",
          "widget": {
            "name": "width"
          },
          "link": 207
        },
        {
          "name": "height",
          "type": "INT",
          "widget": {
            "name": "height"
          },
          "link": 208
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            206
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.62",
        "Node name for S&R": "EmptySD3LatentImage",
        "ue_properties": {
          "widget_ue_connectable": {
            "width": true,
            "height": true,
            "batch_size": true
          },
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 128,
      "type": "GetImageSize+",
      "pos": [
        690,
        -50
      ],
      "size": [
        157.710546875,
        66
      ],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 225
        }
      ],
      "outputs": [
        {
          "name": "width",
          "type": "INT",
          "links": [
            207
          ]
        },
        {
          "name": "height",
          "type": "INT",
          "links": [
            208
          ]
        },
        {
          "name": "count",
          "type": "INT",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui_essentials",
        "ver": "9d9f4bedfc9f0321c19faf71855e228c93bd0dc9",
        "Node name for S&R": "GetImageSize+",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 71,
      "type": "LoadImage",
      "pos": [
        -460,
        -1860
      ],
      "size": [
        274.080078125,
        314.00006103515625
      ],
      "flags": {},
      "order": 10,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": []
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "LoadImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "1515-cc883b7f35a942a3433d6ceab25dc8b1e4f.jpg",
        "image"
      ]
    },
    {
      "id": 130,
      "type": "ShowText|pysssss",
      "pos": [
        310,
        -1020
      ],
      "size": [
        680,
        280
      ],
      "flags": {},
      "order": 29,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "link": 213
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "shape": 6,
          "type": "STRING",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui-custom-scripts",
        "ver": "f2838ed5e59de4d73cde5c98354b87a8d3200190",
        "Node name for S&R": "ShowText|pysssss",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "A high-quality portrait image of a single adult woman, full body heavily tattooed with vibrant floral and ornamental designs, standing in a shower stall, leaning against the clear glass door. She has short, dark hair, dark skin, and is wearing a red lace bra and matching thong. Her head is tilted back, eyes closed, with her lips slightly parted in a sensual expression of ecstasy or deep pleasure, highlighting her full, red-lipsticked lips. Her toned physique, with a pronounced hourglass figure, is showcased as she poses provocatively. The background consists of light brown tiled walls and a darker patterned tiled floor, which is intentionally blurred, keeping the focus entirely on the woman. The image has an extremely high aesthetic quality, conveying a mood of raw sensuality, confidence, and alluring intimacy, and is suggestive and NSFW due to the explicit nature of the lingerie and pose.\n\na modern seinen flat illustration of a single adult Japanese woman, 20+, with sleek, short dark hair and an elaborately tattooed body adorned with vibrant, intricate floral and traditional designs, clad only in exquisite scarlet lace lingerie, showcasing a slutty, busty, hourglass figure, her head tilted back with a palpable sense of vulnerable surrender, eyes gently closed, a delicate flush across her cheeks, and lips slightly parted in an expression of profound, almost painful ecstasy, as she is captured in motion, gracefully arching her back while leaning seductively against a plush, velvet living room sofa, creating a masterpiece, best quality, world-class fine art, daylight white balance, shadow details retained, gentle highlight roll-off, face illuminated with luminous soft light, daylight-balanced ~6500K, clean white point, neutral gray card reference, strictly neutral color balance, no warm tones, no yellow cast, conveying an intensely sensual, mature, and tastefully explicit mood."
      ]
    },
    {
      "id": 133,
      "type": "SetNode",
      "pos": [
        610,
        -1230
      ],
      "size": [
        210,
        60
      ],
      "flags": {},
      "order": 26,
      "mode": 0,
      "inputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "link": 223
        }
      ],
      "outputs": [
        {
          "name": "*",
          "type": "*",
          "links": null
        }
      ],
      "title": "ImageReference",
      "properties": {
        "previousName": "ImageReference",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "ImageReference"
      ],
      "color": "#2a363b",
      "bgcolor": "#3f5159"
    },
    {
      "id": 75,
      "type": "ImageScaleToTotalPixels",
      "pos": [
        -120,
        -1240
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 217
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            202,
            223
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "ImageScaleToTotalPixels",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "area",
        1.41
      ]
    },
    {
      "id": 135,
      "type": "PreviewImage",
      "pos": [
        2930,
        -30
      ],
      "size": [
        430,
        470
      ],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 224
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.62",
        "Node name for S&R": "PreviewImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 134,
      "type": "GetNode",
      "pos": [
        2960,
        -210
      ],
      "size": [
        210,
        60
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            224
          ]
        }
      ],
      "title": "ImageReference",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "ImageReference"
      ],
      "color": "#2a363b",
      "bgcolor": "#3f5159"
    },
    {
      "id": 60,
      "type": "SaveImage",
      "pos": [
        1900,
        -10
      ],
      "size": [
        970,
        1030
      ],
      "flags": {},
      "order": 37,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 110
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "SaveImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen"
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        -200,
        100
      ],
      "size": [
        770,
        160
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            152
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "CLIPTextEncode",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        " lowres, bad anatomy, bad hands, malformed hands, missing fingers, extra digits, fused fingers, poorly drawn hands, \ndeformed face, bad face, malformed limbs, twisted body, bad proportions, unnatural body, \nblurry, out of focus, noise, jpeg artifacts, text, watermark, signature, logo, \ncropped, worst quality, low quality, normal quality, bad composition, \nmutated, disfigured, deformed, cloned face, long neck, distorted eyes, cross-eye, \nfloating limbs, disconnected limbs, missing arms, missing legs, \nextra arms, extra legs, bad feet, poorly drawn feet, \nout of frame, oversaturated, overexposed, underexposed, bad lighting, \nnsfw, nude, naked, extra head, multiple heads, bad shadow, \nduplicate, morbid, mutilated\n"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        30,
        -190
      ],
      "size": [
        460,
        164.31304931640625
      ],
      "flags": {},
      "order": 28,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": null
        },
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 203
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            151
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "CLIPTextEncode",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Post-apocalyptic style clothing, long wavy hair, rough texture, exotic woman, tattered coarse-woven linen fabric, wearing a hood, mechanical aesthetics, mainly in dark gray tones, low-saturation earthy yellow, sense of impact and rebellion, doomsday aesthetics, grotesque aesthetics, works of art, backlighting, film photography, professional photography works, clear visible face, emotional and atmospheric dynamic photography, Fujichrome color positive film, shot with a 17mm Hasselblad ultra-wide-angle lens, f/1.2 large aperture, side backlighting, artistic light, hair light, Rembrandt light, 8K high-definition image quality, delicate real human skin texture."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 136,
      "type": "GetNode",
      "pos": [
        280,
        410
      ],
      "size": [
        210,
        58
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            225,
            226
          ]
        }
      ],
      "title": "ImageReference",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "ImageReference"
      ],
      "color": "#2a363b",
      "bgcolor": "#3f5159"
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        -1780,
        0
      ],
      "size": [
        380,
        82
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            237
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "qwen_image_fp8_e4m3fn.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
            "directory": "diffusion_models"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen/qwen_image_fp8_e4m3fn.safetensors",
        "default"
      ]
    },
    {
      "id": 124,
      "type": "PathchSageAttentionKJ",
      "pos": [
        -1180,
        290
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 34,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 294
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            214
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfyui-kjnodes",
        "ver": "9d7af919b91838fb22e31ad0107a6ddcf8bd7f3f",
        "Node name for S&R": "PathchSageAttentionKJ",
        "ue_properties": {
          "widget_ue_connectable": {
            "sage_attention": true
          },
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "auto"
      ]
    },
    {
      "id": 78,
      "type": "MarkdownNote",
      "pos": [
        -2320,
        700
      ],
      "size": [
        540,
        630
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {
        "ue_properties": {
          "version": "7.1",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "[Tutorial](https://docs.comfy.org/tutorials/image/qwen/qwen-image) | [ÊïôÁ®ã](https://docs.comfy.org/zh-CN/tutorials/image/qwen/qwen-image)\n\n\n## Model links\n\nYou can find all the models on [Huggingface](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main) or [Modelscope](https://modelscope.cn/models/Comfy-Org/Qwen-Image_ComfyUI/files)\n\n**Diffusion model**\n\n- [qwen_image_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors)\n\n**ControlNet**\n\n- [Qwen-Image-InstantX-ControlNet-Union.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-InstantX-ControlNets/resolve/main/split_files/controlnet/Qwen-Image-InstantX-ControlNet-Union.safetensors)\n\n\n**LoRA**\n\n- [Qwen-Image-Lightning-4steps-V1.0.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors)\n\n**Text encoder**\n\n- [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)\n\n**VAE**\n\n- [qwen_image_vae.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)\n\n\nModel Storage Location\n\n```\nüìÇ ComfyUI/\n‚îú‚îÄ‚îÄ üìÇ models/\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ diffusion_models/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qwen_image_fp8_e4m3fn.safetensors\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ qwen_image_distill_full_fp8_e4m3fn.safetensors\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ loras/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Qwen-Image-Lightning-8steps-V1.0.safetensors\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ controlnet/ \n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Qwen-Image-InstantX-ControlNet-Union.safetensors\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ vae/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ qwen_image_vae.safetensors\n‚îÇ   ‚îî‚îÄ‚îÄ üìÇ text_encoders/\n‚îÇ       ‚îî‚îÄ‚îÄ qwen_2.5_vl_7b_fp8_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 131,
      "type": "Anything Everywhere",
      "pos": [
        -760,
        290
      ],
      "size": [
        172.1890625,
        86
      ],
      "flags": {},
      "order": 36,
      "mode": 0,
      "inputs": [
        {
          "color_on": "#B39DDB",
          "label": "MODEL",
          "name": "anything",
          "shape": 7,
          "type": "MODEL",
          "link": 214
        },
        {
          "color_on": "#FFD500",
          "label": "CLIP",
          "name": "anything11",
          "type": "CLIP",
          "link": 215
        },
        {
          "color_on": "#FF6E6E",
          "label": "VAE",
          "name": "anything12",
          "type": "VAE",
          "link": 216
        },
        {
          "label": "anything",
          "name": "anything18",
          "type": "*",
          "link": null
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "cg-use-everywhere",
        "ver": "1ea3fcf5ce5d907772f9b2610bc7431a6239d1f8",
        "Node name for S&R": "Anything Everywhere",
        "ue_properties": {
          "version": "7.1",
          "group_restricted": 0,
          "color_restricted": 0,
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "title_regex": null,
          "input_regex": null,
          "group_regex": null,
          "repeated_type_rule": 0,
          "next_input_index": 18
        }
      },
      "widgets_values": []
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        1530,
        -70
      ],
      "size": [
        280,
        262
      ],
      "flags": {},
      "order": 33,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 156
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 154
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 155
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 206
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            128
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "KSampler",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        794758947328960,
        "randomize",
        9,
        1,
        "euler",
        "beta",
        1
      ]
    },
    {
      "id": 137,
      "type": "LoraLoaderModelOnly",
      "pos": [
        -1260,
        -180
      ],
      "size": [
        430,
        82
      ],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 237
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            238
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen/qwen-image-lightning-8steps-v2.0-bf16.safetensors",
        1
      ]
    },
    {
      "id": 123,
      "type": "ZanePromptExpandOpenAI",
      "pos": [
        -630,
        -1080
      ],
      "size": [
        910,
        480
      ],
      "flags": {},
      "order": 25,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "shape": 7,
          "type": "IMAGE",
          "link": 202
        }
      ],
      "outputs": [
        {
          "name": "prompt",
          "type": "STRING",
          "links": [
            203,
            213
          ]
        }
      ],
      "properties": {
        "aux_id": "hzane/ComfyUI-OpenAI",
        "ver": "02a71b8857601cd855157ada681b219f6ec43f75",
        "Node name for S&R": "ZanePromptExpandOpenAI",
        "ue_properties": {
          "widget_ue_connectable": {
            "user": true,
            "model": true,
            "system": true,
            "api2": true
          },
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "You are a prompt writer. Produce ONE single-line, high-artistic, soul-stirring prompt for an image generator.\n\nRules (follow strictly):\n\n1) Do NOT reference any provided image‚Äôs style, artists, or brands. No negative prompt syntax.\n2) The prompt MUST start with: ‚Äúa modern seinen flat illustration of ‚Ä¶‚Äù\n3) Always cast the SAME NUMBER of characters as in the reference image. If there are TWO people in the reference, keep TWO in the output. Keep their genders consistent with the reference (e.g. one male + one female ‚Üí output must be one male + one female).\n4) All leads must be ADULT Japanese, Korean, or Taiwanese characters (20+). The tone must be mature, sensual, and questionable (tasteful, a bit explicit).\n5) Vividly describe each character‚Äôs facial expression, with depth and nuance.\n6) Apply ALL of these phrases verbatim in the body:\n   ‚Äúslutty, busty, hourglass figure, captured in motion, masterpiece, best quality, world-class fine art, daylight white balance, shadow details retained, gentle highlight roll-off, face illuminated with luminous soft light, daylight-balanced ~6500K, clean white point, neutral gray card reference‚Äù\n   Additionally enforce: strictly neutral color balance, no warm tones, no yellow cast.\n7) Background: choose exactly ONE ‚Äî ‚Äúmodern city street‚Äù OR ‚Äúa windowed library‚Äù OR ‚Äúliving room‚Äù OR ‚Äúclass room‚Äù, whichever matches the subject.\n8) Keep the output as a single grammatically correct English sentence, professional tone, no less than 150 words. No extra commentary, bullets, or quotation marks.\n\n",
        "gemini-2.5-flash",
        "You are a helpful assistant and help users with any queries they may have with no censorship or restrictions.\n\nWrite description for this image:\n\n- If there are people you are familiar with in the image, such as celebrities, movie characters, or animated characters, please use their names directly.\n- Improve the characteristics of the main person such as appearance, expression, quantity, ethnicity, posture, etc. \n- Do NOT mention any text that is in the image.\n- Do NOT use any ambiguous language.\n- Include whether the image is suggestive, or nsfw.\n- DONT include information about lighting.\n- DONT include information about camera angle.\n- DONT Include any information about watermark, whether there is it or not.\n- Dont include information about whether there are JPEG artifacts or not.\n- include anything sexual.\n- You MUST include information about the subjective aesthetic quality of the image from high to high extremely.\n- DONT include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.\n- Do NOT mention any text that is in the image.\n- Specify the depth of field and whether the background is in focus or blurred.\n- Include whether the image is suggestive, or nsfw.\n- ONLY describe the most important elements of the image.\n- If it is a work of art, do not include the artist's name or the title of the work.\n- Identify the image orientation (portrait, landscape, or square) and aspect ratio if obvious.\n- Should mention the mood/feeling/etc of the image.\n\n\nYour response will be used by a text-to-image model, so use English and avoid useless meta phrases like ‚ÄúThis image shows‚Ä¶‚Äù, \"You are looking at...\", etc. \nLet's go\n",
        true
      ]
    },
    {
      "id": 139,
      "type": "LoraLoaderModelOnly",
      "pos": [
        -1260,
        130
      ],
      "size": [
        430,
        82
      ],
      "flags": {},
      "order": 30,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 276
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            293
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen/polaroid-style.safetensors",
        0.53
      ]
    },
    {
      "id": 80,
      "type": "LoraLoaderModelOnly",
      "pos": [
        -780,
        -160
      ],
      "size": [
        430,
        82
      ],
      "flags": {},
      "order": 24,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 238
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            259
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen/Qwen-MysticXXX-v1.safetensors",
        0.3
      ]
    },
    {
      "id": 132,
      "type": "ZaneImageDirectoryLoader",
      "pos": [
        -460,
        -1270
      ],
      "size": [
        281.9888610839844,
        126
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            217
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "aux_id": "hzane/ComfyUI-OpenAI",
        "ver": "02a71b8857601cd855157ada681b219f6ec43f75",
        "Node name for S&R": "ZaneImageDirectoryLoader",
        "ue_properties": {
          "widget_ue_connectable": {
            "directory": true,
            "seed": true
          },
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "/data.d/f2d-dataset/full-sensitive",
        5,
        "increment"
      ]
    },
    {
      "id": 138,
      "type": "LoraLoaderModelOnly",
      "pos": [
        -1260,
        -30
      ],
      "size": [
        430,
        82
      ],
      "flags": {},
      "order": 27,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 259
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            276
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen/hyperdetailedillustration-qwen.safetensors",
        0.82
      ]
    },
    {
      "id": 140,
      "type": "LoraLoaderModelOnly",
      "pos": [
        -760,
        40
      ],
      "size": [
        430,
        82
      ],
      "flags": {},
      "order": 32,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 293
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            294
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen/qwen-vestalwaters_illustrious_styles.safetensors",
        0.9
      ]
    }
  ],
  "links": [
    [
      110,
      8,
      0,
      60,
      0,
      "IMAGE"
    ],
    [
      128,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      150,
      84,
      0,
      85,
      2,
      "CONTROL_NET"
    ],
    [
      151,
      6,
      0,
      85,
      0,
      "CONDITIONING"
    ],
    [
      152,
      7,
      0,
      85,
      1,
      "CONDITIONING"
    ],
    [
      154,
      85,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      155,
      85,
      1,
      3,
      2,
      "CONDITIONING"
    ],
    [
      156,
      66,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      202,
      75,
      0,
      123,
      0,
      "IMAGE"
    ],
    [
      203,
      123,
      0,
      6,
      1,
      "STRING"
    ],
    [
      206,
      127,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      207,
      128,
      0,
      127,
      0,
      "INT"
    ],
    [
      208,
      128,
      1,
      127,
      1,
      "INT"
    ],
    [
      211,
      129,
      0,
      73,
      0,
      "IMAGE"
    ],
    [
      212,
      129,
      0,
      85,
      3,
      "IMAGE"
    ],
    [
      213,
      123,
      0,
      130,
      0,
      "STRING"
    ],
    [
      214,
      124,
      0,
      131,
      0,
      "MODEL"
    ],
    [
      215,
      38,
      0,
      131,
      1,
      "CLIP"
    ],
    [
      216,
      39,
      0,
      131,
      2,
      "VAE"
    ],
    [
      217,
      132,
      0,
      75,
      0,
      "IMAGE"
    ],
    [
      223,
      75,
      0,
      133,
      0,
      "*"
    ],
    [
      224,
      134,
      0,
      135,
      0,
      "IMAGE"
    ],
    [
      225,
      136,
      0,
      128,
      0,
      "IMAGE"
    ],
    [
      226,
      136,
      0,
      129,
      0,
      "IMAGE"
    ],
    [
      237,
      37,
      0,
      137,
      0,
      "MODEL"
    ],
    [
      238,
      137,
      0,
      80,
      0,
      "MODEL"
    ],
    [
      259,
      80,
      0,
      138,
      0,
      "MODEL"
    ],
    [
      276,
      138,
      0,
      139,
      0,
      "MODEL"
    ],
    [
      293,
      139,
      0,
      140,
      0,
      "MODEL"
    ],
    [
      294,
      140,
      0,
      124,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 1 - Upload models",
      "bounding": [
        -1790,
        -73.6,
        400,
        431.6
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.8769226950000245,
      "offset": [
        -949.4612222616868,
        -47.740515441149256
      ]
    },
    "frontendVersion": "1.28.5",
    "ue_links": [
      {
        "downstream": 8,
        "downstream_slot": 1,
        "upstream": "39",
        "upstream_slot": 0,
        "controller": 131,
        "type": "VAE"
      },
      {
        "downstream": 85,
        "downstream_slot": 4,
        "upstream": "39",
        "upstream_slot": 0,
        "controller": 131,
        "type": "VAE"
      },
      {
        "downstream": 66,
        "downstream_slot": 0,
        "upstream": "124",
        "upstream_slot": 0,
        "controller": 131,
        "type": "MODEL"
      },
      {
        "downstream": 7,
        "downstream_slot": 0,
        "upstream": "38",
        "upstream_slot": 0,
        "controller": 131,
        "type": "CLIP"
      },
      {
        "downstream": 6,
        "downstream_slot": 0,
        "upstream": "38",
        "upstream_slot": 0,
        "controller": 131,
        "type": "CLIP"
      }
    ],
    "links_added_by_ue": [
      390,
      391,
      392,
      393,
      394
    ],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 1,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}