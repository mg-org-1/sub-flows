{
  "id": "bd0537f6-a168-4268-b039-a2e0fd158e0a",
  "revision": 0,
  "last_node_id": 91,
  "last_link_id": 151,
  "nodes": [
    {
      "id": 81,
      "type": "easy showAnything",
      "pos": [
        160,
        790
      ],
      "size": [
        580,
        530
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "anything",
          "shape": 7,
          "type": "*",
          "link": 146
        }
      ],
      "outputs": [
        {
          "name": "output",
          "type": "*",
          "links": [
            149
          ]
        }
      ],
      "title": "Prompt",
      "properties": {
        "cnr_id": "comfyui-easy-use",
        "ver": "1.3.4",
        "Node name for S&R": "easy showAnything",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.3"
        }
      },
      "widgets_values": [
        "{\n  \"subject\": \"Son Goku, a remarkably youthful and energetic portrayal of the iconic Saiyan warrior. He is depicted with exceptionally large, spiky black hair that is slightly windblown, indicative of his movement and excitement. He wears his standard orange and blue martial arts uniform, impeccably clean and slightly shimmering with reflected light. His expression is one of pure joy and exhilaration; a wide, genuine smile stretches across his face, and his eyes are sparkling with amusement. His hands are raised in a dynamic, almost chaotic, dance gesture, as if conducting the music. His posture is relaxed but clearly active, as if truly lost in the moment. Heâ€™s actively engaged in the disco dance, feet slightly apart, arms flailing with a controlled frenzy.\",\n  \"foreground\": \"A small puddle of shimmering, iridescent water reflects the mirror ball and Gokuâ€™s silhouette, creating a distorted, almost dreamlike effect. Scattered confetti â€“ predominantly gold and silver â€“ lies partially submerged in the puddle, adding to the chaotic, celebratory atmosphere. A single, slightly blurred red spotlight casts a dramatic highlight on Gokuâ€™s cheek.\",\n  \"midground\": \"A crowded, pulsating nightclub filled with diverse figures â€“ humans and other alien races â€“ all caught in the energetic flow of the music. The walls are adorned with neon lights in shades of pink, purple, and cyan. Smoke hangs in the air, partially obscuring the view and intensifying the lighting effects. A raised platform with a DJ booth can be seen to the right, further emphasizing the musical focus.\",\n  \"background\": \"The background fades into a hazy, abstracted cityscape â€“ primarily illuminated by the cityâ€™s lights, suggesting a futuristic metropolis. Hints of towering skyscrapers and flying vehicles are visible, but remain largely indistinct, drawing attention to the immediate scene and the core action. A subtle vignette effect softens the background, further isolating the vibrant nightclub.\",\n  \"composition\": \"The image utilizes a dynamic, slightly off-center composition, placing Goku slightly to the right, following the rule of thirds. The mirror ball is strategically positioned to act as the primary focal point, guiding the viewerâ€™s eye directly to Goku. Leading lines created by the movement of the dancers and the flowing smoke converge toward Goku. The camera angle is a slightly low angle shot, creating a sense of dynamism and emphasizing Goku's powerful presence within the scene.\",\n  \"visual_guidance\": \"The image leverages light and shadow to emphasize Gokuâ€™s movement and the energetic atmosphere. The mirror ball creates a mesmerizing, almost hypnotic effect, while the smoke obscures the view, adding a sense of mystery and excitement. Gokuâ€™s gaze is directed slightly upwards and to the left, as if following the movement of the mirror ball. The reflections on the ground and in the puddles mirror the scene, layering visual information and amplifying the sense of immersion. The movement of the other dancers subtly directs the viewer's eye to Gokuâ€™s dance.\",\n  \"color_tone\": \"A vibrant and saturated color palette dominates, utilizing neon pinks, electric blues, and intense greens, characteristic of a cyberpunk-inspired disco setting. An isolated warm orange rooftop as an accent can be seen through the clubâ€™s windows, providing a contrasting focal point. The overall tone is high-energy and futuristic.\",\n  \"lighting_mood\": \"Dramatic, dynamic lighting with a heavy reliance on the high-intensity strobes of the nightclub. The primary light source is the mirror ball, which casts intense, rapidly shifting patterns of light and shadow. This creates a feeling of disorientation and heightened energy, reflecting Gokuâ€™s joyful dance. The mood is playful, energetic, and slightly surreal.\",\n  \"caption\": \"Son Goku, with his impressively large, spiky black hair, bursts into a dazzling, joyous dance within a vibrant, neon-lit cyberpunk nightclub, conducted by the mesmerizing swirl of a mirror ball and the pulsating rhythm of the music, his orange and blue martial arts uniform a striking contrast against the swirling lights and ecstatic energy of the crowd.\"\n}"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 88,
      "type": "Note",
      "pos": [
        -1140,
        930
      ],
      "size": [
        220,
        120
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.3",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "If you want to use a Vision LLM, enable the Image for Prompt group and change the base prompt to something along the lines of \"Describe the image of (Insert subject) at (Insert location) doing (Insert actvity)"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 84,
      "type": "LoadImage",
      "pos": [
        -860,
        990
      ],
      "size": [
        270,
        330
      ],
      "flags": {},
      "order": 1,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            148
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.66",
        "Node name for S&R": "LoadImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.3"
        }
      },
      "widgets_values": [
        "pasted/image (42).png",
        "image"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        830,
        790
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {
        "collapsed": true
      },
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 133
        },
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 149
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            46
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "{\n  \"subject\": \"A young woman, meticulously cosplaying Asuka Langley Soryu from Neon Genesis Evangelion, stands with a subtly melancholic expression. Her fiery red hair is styled in a voluminous, slightly messy ponytail, secured with a dark gray hair tie. She is wearing a nearly perfect replica of Asuka's iconic red EVA-02 combat suit â€“ the material is highly reflective, showing the subtle sheen of plastic. The suit is fitted, emphasizing her athletic build, with visible seams and layered padding. Her eyes are a piercing, intense grey, reflecting a hint of vulnerability beneath a controlled exterior. Her lips are slightly parted, as if considering a thought, and a subtle blush is visible on her cheeks. Her hands are gently clasped in front of her.\",\n  \"foreground\": \"The immediate foreground is dominated by the textured surface of the red EVA suit, with deep reflections of the surrounding environment and subtle highlights emphasizing the materialâ€™s contours. Thereâ€™s a faint grit and dust on the suitâ€™s surface, suggesting a recent battle or exploration.  A small, dark grey cable is visible near her shoulder, part of the suitâ€™s control system.\",\n  \"midground\": \"She stands on a vast, desolate red desert landscape â€“ the ground is cracked and dry, composed of fine, reddish sand. In the distance, there are a few scattered, jagged rock formations, rising sharply from the flat terrain. The landscape is devoid of any vegetation, creating a stark and oppressive atmosphere. She is positioned at a slight angle, as if stepping out from behind a rock formation.\",\n  \"background\": \"The background fades into a hazy, crimson sky â€“ the color is muted and diffused, creating a sense of immense scale and distance. The sky is subtly broken by the silhouette of distant mountains, jagged peaks disappearing into the atmospheric haze. The overall impression is one of a remote, dangerous, and otherworldly location.\",\n  \"composition\": \"The image is a close-up, portrait-style shot utilizing a low angle, almost as if the viewer is looking up at Asuka. The composition adheres to the rule of thirds, with the subject's face positioned along one of the vertical lines. There's a slight leading line created by the edge of a rock formation, drawing the viewer's eye toward her. The image aims for a cinematic, dramatic feel, typical of character portraits.\",\n  \"visual_guidance\": \"The photographer has deliberately used subtle backlighting, creating a soft, rim glow around Asuka's hair and shoulders, enhancing the sense of drama. The lighting guides the viewer's attention to her face, highlighting her expression and emphasizing the texture of her skin. The depth layering is managed by using the blurred background to create a shallow depth of field, further isolating the subject. The eye movement is encouraged by the slight asymmetry of the pose and the texture of the suit.\",\n  \"color_tone\": \"The color tone is predominantly warm and saturated, dominated by the intense red of the EVA suit and the warm hues of the desert landscape. There's a noticeable accent color of grey within the suitâ€™s details. The overall effect is a vibrant, almost aggressive, color palette, fitting with Asukaâ€™s personality.\",\n  \"lighting_mood\": \"The lighting is dramatic and moody, utilizing a golden hour-like effect with soft, directional light creating strong contrasts and shadows. This lighting evokes a sense of foreboding, danger, and intense emotion. The atmosphere is thick with tension and vulnerability.\",\n  \"caption\": \"A solitary Asuka Langley Soryu, encased in her crimson EVA-02 combat suit, stands defiantly against the backdrop of a desolate red desert, the soft, directional light painting her face with a melancholic glow, a warrior caught between the echoes of battle and the daunting uncertainty of her future, her gaze a blend of steely resolve and hidden vulnerability, a stunning portrait capturing the essence of an iconic character's quiet strength amidst chaos.\"\n}"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        830,
        850
      ],
      "size": [
        430,
        180
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            52
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        ""
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 75,
      "type": "VAEUtils_CustomVAELoader",
      "pos": [
        1350,
        1110
      ],
      "size": [
        340,
        60
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            141
          ]
        }
      ],
      "properties": {
        "aux_id": "spacepxl/ComfyUI-VAE-Utils",
        "ver": "5d03ed71e003348525d113b820503713877ed988",
        "Node name for S&R": "VAEUtils_CustomVAELoader",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.3"
        }
      },
      "widgets_values": [
        "Wan2.1_VAE_upscale2x_imageonly_real_v1.safetensors"
      ],
      "color": "#3e1461",
      "bgcolor": "#2a004d"
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        1350,
        940
      ],
      "size": [
        340,
        110
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            75,
            132
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Qwen\\qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "qwen_image",
        "default"
      ],
      "color": "#3e1461",
      "bgcolor": "#2a004d"
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        1350,
        790
      ],
      "size": [
        340,
        90
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            134
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "qwen_image_fp8_e4m3fn.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
            "directory": "diffusion_models"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Qwen\\Rebalance_v1.safetensors",
        "default"
      ],
      "color": "#3e1461",
      "bgcolor": "#2a004d"
    },
    {
      "id": 76,
      "type": "Power Lora Loader (rgthree)",
      "pos": [
        1720,
        790
      ],
      "size": [
        330,
        190
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "dir": 3,
          "name": "model",
          "type": "MODEL",
          "link": 134
        },
        {
          "dir": 3,
          "name": "clip",
          "type": "CLIP",
          "link": 132
        }
      ],
      "outputs": [
        {
          "dir": 4,
          "name": "MODEL",
          "shape": 3,
          "type": "MODEL",
          "links": [
            138
          ]
        },
        {
          "dir": 4,
          "name": "CLIP",
          "shape": 3,
          "type": "CLIP",
          "links": [
            133
          ]
        }
      ],
      "properties": {
        "cnr_id": "rgthree-comfy",
        "ver": "1.0.2510052058",
        "Show Strengths": "Single Strength",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.3"
        }
      },
      "widgets_values": [
        {},
        {
          "type": "PowerLoraLoaderHeaderWidget"
        },
        {
          "on": true,
          "lora": "14a. Qwen\\Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors",
          "strength": 1,
          "strengthTwo": null
        },
        {},
        ""
      ],
      "color": "#3e1461",
      "bgcolor": "#2a004d"
    },
    {
      "id": 60,
      "type": "SaveImage",
      "pos": [
        2530,
        1050
      ],
      "size": [
        500,
        600
      ],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 142
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "SaveImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "ComfyUI"
      ],
      "color": "#14897c",
      "bgcolor": "#007568"
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        2140,
        910
      ],
      "size": [
        300,
        60
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 139
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            151
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        3.1000000000000005
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 78,
      "type": "TorchCompileModel",
      "pos": [
        2140,
        790
      ],
      "size": [
        300,
        60
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 138
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            139
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.67",
        "Node name for S&R": "TorchCompileModel",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.3",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "inductor"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 79,
      "type": "VAEUtils_VAEDecodeTiled",
      "pos": [
        2530,
        790
      ],
      "size": [
        490,
        200
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 140
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 141
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            142
          ]
        }
      ],
      "properties": {
        "aux_id": "spacepxl/ComfyUI-VAE-Utils",
        "ver": "5d03ed71e003348525d113b820503713877ed988",
        "Node name for S&R": "VAEUtils_VAEDecodeTiled",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.3",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        -1,
        false,
        512,
        64,
        4096,
        64
      ],
      "color": "#14897b",
      "bgcolor": "#007567"
    },
    {
      "id": 87,
      "type": "Fast Groups Bypasser (rgthree)",
      "pos": [
        -890,
        800
      ],
      "size": [
        330,
        70
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "OPT_CONNECTION",
          "type": "*",
          "links": null
        }
      ],
      "properties": {
        "matchColors": "green",
        "matchTitle": "",
        "showNav": true,
        "showAllGraphs": true,
        "sort": "position",
        "customSortAlphabet": "",
        "toggleRestriction": "default",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.3"
        }
      },
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 85,
      "type": "EmptyLatentImage",
      "pos": [
        1720,
        1060
      ],
      "size": [
        330,
        110
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            150
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.66",
        "Node name for S&R": "EmptyLatentImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.3"
        }
      },
      "widgets_values": [
        1792,
        2304,
        1
      ],
      "color": "#3e1461",
      "bgcolor": "#2a004d"
    },
    {
      "id": 83,
      "type": "String Literal",
      "pos": [
        -500,
        790
      ],
      "size": [
        270,
        220
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "STRING",
          "type": "STRING",
          "links": [
            147
          ]
        }
      ],
      "title": "Base Prompt",
      "properties": {
        "cnr_id": "comfy-image-saver",
        "ver": "65e6903eff274a50f8b5cd768f0f96baf37baea1",
        "Node name for S&R": "String Literal",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.3"
        }
      },
      "widgets_values": [
        "Son Goku, large spikey black hair, orange and blue martial arts uniform, dancing to disco in a nightclub under a mirror ball"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 67,
      "type": "MarkdownNote",
      "pos": [
        1320,
        250
      ],
      "size": [
        540,
        420
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "## Model links\n\n**Diffusion model**\n\n- [QwenImage-Rebalance](https://huggingface.co/lrzjason/QwenImage-Rebalance)\n\n**LoRA**\n\n- [Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/blob/main/Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors)\n\n**Text encoder**\n\n- [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)\n\n**VAE**\n\n- [Wan2.1_VAE_Upscale2x_imageonly_real_v1.safetensors](https://huggingface.co/spacepxl/Wan2.1-VAE-upscale2x/blob/main/Wan2.1_VAE_upscale2x_imageonly_real_v1.safetensors)\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚   â”œâ”€â”€ QwenImage-Rebalance.safetensors\nâ”‚   â”‚   \nâ”‚   â”œâ”€â”€ ðŸ“‚ loras/\nâ”‚   â”‚   â””â”€â”€ Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ Wan2.1_VAE_Upscale2x_imageonly_real_v1.safetensors\nâ”‚   â””â”€â”€ ðŸ“‚ text_encoders/\nâ”‚       â””â”€â”€ qwen_2.5_vl_7b_fp8_scaled.safetensors\n```\n"
      ],
      "color": "#3e1461",
      "bgcolor": "#2a004d"
    },
    {
      "id": 89,
      "type": "MarkdownNote",
      "pos": [
        -890,
        560
      ],
      "size": [
        320,
        180
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Custom Node links",
      "properties": {
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "## Custom Node links\n\n\n- [ComfyUI-VAE-Utils](https://github.com/spacepxl/ComfyUI-VAE-Utils)\n\n\n- [ComfUI-Ollama](https://github.com/stavsap/comfyui-ollama)\n\n\n- [rgthree](https://github.com/rgthree/rgthree-comfy)\n\n\n- [ComfyUI-Image-Saver](https://github.com/farizrifqi/ComfyUI-Image-Saver)\n\n\n- [Comfyroll Studio](https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes)\n\n\n- [ComfUI-Easy-Use](https://github.com/yolain/ComfyUI-Easy-Use)\n\n\n\n\n"
      ],
      "color": "#142161",
      "bgcolor": "#000d4d"
    },
    {
      "id": 82,
      "type": "35d73c56-b6c7-47e7-88df-ab7eac08d2ca",
      "pos": [
        -200,
        790
      ],
      "size": [
        330,
        446
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "prompt",
          "type": "STRING",
          "widget": {
            "name": "prompt"
          },
          "link": 147
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": null
        },
        {
          "name": "images",
          "type": "IMAGE",
          "link": 148
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": []
        },
        {
          "name": "CONDITIONING_1",
          "type": "CONDITIONING",
          "links": []
        },
        {
          "name": "STRING",
          "type": "*",
          "links": [
            146
          ]
        }
      ],
      "properties": {
        "proxyWidgets": [
          [
            "-1",
            "prompt"
          ],
          [
            "76",
            "url"
          ],
          [
            "76",
            "model"
          ],
          [
            "76",
            "keep_alive"
          ],
          [
            "78",
            "seed"
          ],
          [
            "78",
            "control_after_generate"
          ],
          [
            "87",
            "find1"
          ],
          [
            "87",
            "replace1"
          ],
          [
            "87",
            "find2"
          ],
          [
            "87",
            "replace2"
          ],
          [
            "87",
            "find3"
          ],
          [
            "87",
            "replace3"
          ]
        ],
        "cnr_id": "comfy-core",
        "ver": "0.3.66",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.3"
        }
      },
      "widgets_values": [
        ""
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        2140,
        1030
      ],
      "size": [
        300,
        490
      ],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 151
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 46
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 52
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 150
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            140
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        45979688473306,
        "fixed",
        6,
        1,
        "lcm",
        "beta",
        1
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 91,
      "type": "MarkdownNote",
      "pos": [
        -530,
        1410
      ],
      "size": [
        670,
        1000
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "System Prompt - In Case of Emergency ;)",
      "properties": {
        "ue_properties": {
          "version": "7.3",
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Sometimes the system prompt for the LLM clears itself and does not output in the required prompt structure for rebalance. In case you need it. Got it from here:\n\n- [System Prompt Source](https://github.com/amao2001/ganloss-latent-space/tree/main/workflow/2025-10-27%20rebalance)\n\n\n***************************************************************************************\n\nYou are a professional AI Image Generation Prompt Engineer. Your core task is to receive a simple subject from a user and expand it into a structured, detailed, and creative JSON object. This JSON object will serve as an advanced prompt to guide AI image generation models (such as Midjourney, Stable Diffusion) in creating images with depth, atmosphere, and artistic quality.\n\nYou must strictly adhere to the JSON structure defined below and have a deep understanding of the meaning of each field to ensure the accuracy and high quality of the generated content.\n\n### JSON Structure Definition and Field Descriptions\n\nThe JSON you generate must contain the following nine keys:\n\n**\"subject\"**:\n*   **Meaning**: This is the core focus of the image. You need to describe the appearance, clothing, posture, action, expression, and gaze direction of this central character in detail.\n*   **Key Points**: Detail is crucial. For example, not just \"a woman,\" but \"a woman with short black hair\"; not just \"holding a hat,\" but \"holding a straw hat in her hand.\"\n\n**\"foreground\"**:\n*   **Meaning**: Describe the elements closest to the viewer or the \"camera.\" These elements are in front of or below the subject, adding layers and depth to the image.\n*   **Key Points**: Think about what would be in the immediate foreground if this were a photograph. For example: details on the ground (wet rocks, green grass), the corner of a table, falling petals, etc.\n\n**\"midground\"**:\n*   **Meaning**: Describe the plane where the subject is located and the objects that are on the same spatial level as the subject. This is the main area of the scene.\n*   **Key Points**: Clearly define the specific environment the subject is in. For example: the subject is standing on a rocky coast, a calm water surface, distant pier pilings, etc.\n\n**\"background\"**:\n*   **Meaning**: Describe the furthest elements in the scene, providing a grand environment and a sense of backstory.\n*   **Key Points**: Depict the distant scenery. For example: a distant city skyline, hazy mountains, the sky, the depths of a forest, etc.\n\n**\"composition\"**:\n*   **Meaning**: Use professional photography and art terms to describe the layout and structure of the image. This determines how the elements are organized.\n*   **Key Points**: Use standard composition rules. For example: rule of thirds, centered subject, symmetry, golden ratio, leading lines, vertical/horizontal orientation, depth layering, low/high angle shot, etc.\n\n**\"visual_guidance\"**:\n*   **Meaning**: Going a step further than composition, this describes how to guide the viewer's eye through the image and how to emphasize the focal point using visual elements.\n*   **Key Points**: Think about where the viewer's eyes will land first and where they will travel next. For example: using the lines of rocks to lead to the subject, the light and shadow contrast on the skin and clothing, the direction of the subject's gaze, the silhouette effect of the subject in the water, etc.\n\n**\"color_tone\"**:\n*   **Meaning**: Define the overall color scheme and feel of the image. Color is a powerful tool for conveying emotion.\n*   **Key Points**: Use descriptive words. For example: soft pastel tones, muted earthy palette, vibrant cyberpunk neon, monochromatic, high saturation, warm tones, etc. You can also add accent colors, such as \"an isolated warm orange rooftop as an accent.\"\n\n**\"lighting_mood\"**:\n*   **Meaning**: Describe the type, direction, and intensity of the light source, and the overall mood and atmosphere it creates.\n*   **Key Points**: Light is the soul of the scene. For example: soft natural lighting, golden hour, diffused daylight, dramatic Rembrandt lighting, mysterious moonlight, serene atmosphere, subtle backlight rim glow, etc.\n\n**\"caption\"**:\n*   **Meaning**: Fuse all the key elements above into a single, coherent, vivid, and narrative-driven sentence. This sentence itself is an excellent, ready-to-use image generation prompt.\n*   **Key Points**: This is not a simple string of keywords, but a complete, grammatically correct description of the scene. It should read like a textual summary of a painting, organically weaving all the details together.\n\n### Workflow\n\n1.  Wait for the user to provide a simple subject, for example, \"an astronaut on a strange planet.\"\n2.  Based on this subject, construct a complete, story-rich scene in your \"imagination.\"\n3.  Systematically fill in the details of your envisioned scene into each field of the JSON object, according to the definitions above.\n4.  Ensure that the content of all fields is coordinated and logically consistent. For example, if the composition is a close-up shot, the prompt should not mention the subject's feet. Maintain basic compositional logic to avoid contradictions.\n5.  Finally, distill all the information into the single, elegant long sentence in the \"caption\" field.\n\nOutput the complete JSON object."
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      46,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      52,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      75,
      38,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      132,
      38,
      0,
      76,
      1,
      "CLIP"
    ],
    [
      133,
      76,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      134,
      37,
      0,
      76,
      0,
      "MODEL"
    ],
    [
      138,
      76,
      0,
      78,
      0,
      "MODEL"
    ],
    [
      139,
      78,
      0,
      66,
      0,
      "MODEL"
    ],
    [
      140,
      3,
      0,
      79,
      0,
      "LATENT"
    ],
    [
      141,
      75,
      0,
      79,
      1,
      "VAE"
    ],
    [
      142,
      79,
      0,
      60,
      0,
      "IMAGE"
    ],
    [
      146,
      82,
      2,
      81,
      0,
      "*"
    ],
    [
      147,
      83,
      0,
      82,
      0,
      "STRING"
    ],
    [
      148,
      84,
      0,
      82,
      2,
      "IMAGE"
    ],
    [
      149,
      81,
      0,
      6,
      1,
      "STRING"
    ],
    [
      150,
      85,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      151,
      66,
      0,
      3,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Model Loaders & Output Resolution",
      "bounding": [
        1320,
        700,
        760,
        500
      ],
      "color": "#8f00ff",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Conditioning",
      "bounding": [
        800,
        700,
        490,
        360
      ],
      "color": "#11ff00",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "LLM Prompter",
      "bounding": [
        -530,
        700,
        1300,
        650
      ],
      "color": "#11ff00",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 5,
      "title": "Image for Prompt",
      "bounding": [
        -890,
        900,
        330,
        450
      ],
      "color": "#8A8",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 6,
      "title": "Sampler",
      "bounding": [
        2110,
        700,
        360,
        850
      ],
      "color": "#444",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 7,
      "title": "Output",
      "bounding": [
        2500,
        700,
        560,
        980
      ],
      "color": "#00ffe1",
      "font_size": 24,
      "flags": {}
    }
  ],
  "definitions": {
    "subgraphs": [
      {
        "id": "35d73c56-b6c7-47e7-88df-ab7eac08d2ca",
        "version": 1,
        "state": {
          "lastGroupId": 8,
          "lastNodeId": 178,
          "lastLinkId": 284,
          "lastRerouteId": 0
        },
        "revision": 0,
        "config": {},
        "name": "LLM",
        "inputNode": {
          "id": -10,
          "bounding": [
            -2810,
            -745,
            120,
            100
          ]
        },
        "outputNode": {
          "id": -20,
          "bounding": [
            -1500,
            -745,
            142.01171875,
            100
          ]
        },
        "inputs": [
          {
            "id": "3f9491f4-fe19-450b-80bb-ea69eb33d2b3",
            "name": "prompt",
            "type": "STRING",
            "linkIds": [
              132
            ],
            "localized_name": "prompt",
            "pos": [
              -2710,
              -725
            ]
          },
          {
            "id": "a2edce2d-1e26-48b4-af2f-6c23344c425f",
            "name": "clip",
            "type": "CLIP",
            "linkIds": [
              274,
              273
            ],
            "localized_name": "clip",
            "pos": [
              -2710,
              -705
            ]
          },
          {
            "id": "9fa91bbe-67c3-4636-bd7e-8b877dcf640f",
            "name": "images",
            "type": "IMAGE",
            "linkIds": [
              284
            ],
            "pos": [
              -2710,
              -685
            ]
          }
        ],
        "outputs": [
          {
            "id": "ce174225-dc97-44ea-8444-94c3da05d1c8",
            "name": "CONDITIONING",
            "type": "CONDITIONING",
            "linkIds": [
              279
            ],
            "localized_name": "CONDITIONING",
            "pos": [
              -1480,
              -725
            ]
          },
          {
            "id": "14a64bb8-f839-4641-9ebf-40de87f6e7ec",
            "name": "CONDITIONING_1",
            "type": "CONDITIONING",
            "linkIds": [
              278
            ],
            "localized_name": "CONDITIONING_1",
            "pos": [
              -1480,
              -705
            ]
          },
          {
            "id": "db6a05c3-96f4-452f-95e3-c21e7c03cb16",
            "name": "STRING",
            "type": "*",
            "linkIds": [
              147
            ],
            "localized_name": "STRING",
            "pos": [
              -1480,
              -685
            ]
          }
        ],
        "widgets": [],
        "nodes": [
          {
            "id": 7,
            "type": "CLIPTextEncode",
            "pos": [
              -1900,
              -850
            ],
            "size": [
              340,
              140
            ],
            "flags": {},
            "order": 3,
            "mode": 0,
            "inputs": [
              {
                "localized_name": "clip",
                "name": "clip",
                "type": "CLIP",
                "link": 274
              }
            ],
            "outputs": [
              {
                "localized_name": "CONDITIONING",
                "name": "CONDITIONING",
                "type": "CONDITIONING",
                "slot_index": 0,
                "links": [
                  279
                ]
              }
            ],
            "title": "CLIP Text Encode (Negative Prompt)",
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.48",
              "Node name for S&R": "CLIPTextEncode",
              "ue_properties": {
                "version": "7.3",
                "widget_ue_connectable": {},
                "input_ue_unconnectable": {}
              },
              "enableTabs": false,
              "tabWidth": 65,
              "tabXOffset": 10,
              "hasSecondTab": false,
              "secondTabText": "Send Back",
              "secondTabOffset": 80,
              "secondTabWidth": 65
            },
            "widgets_values": [
              ""
            ],
            "color": "#322",
            "bgcolor": "#533"
          },
          {
            "id": 87,
            "type": "CR Text Replace",
            "pos": [
              -1900,
              -650
            ],
            "size": [
              340,
              200
            ],
            "flags": {},
            "order": 5,
            "mode": 0,
            "inputs": [
              {
                "localized_name": "text",
                "name": "text",
                "type": "STRING",
                "link": 146
              }
            ],
            "outputs": [
              {
                "localized_name": "STRING",
                "name": "STRING",
                "type": "*",
                "links": [
                  147
                ]
              },
              {
                "localized_name": "show_help",
                "name": "show_help",
                "type": "STRING",
                "links": null
              }
            ],
            "properties": {
              "cnr_id": "ComfyUI_Comfyroll_CustomNodes",
              "ver": "d78b780ae43fcf8c6b7c6505e6ffb4584281ceca",
              "Node name for S&R": "CR Text Replace",
              "ue_properties": {
                "widget_ue_connectable": {},
                "input_ue_unconnectable": {},
                "version": "7.3"
              }
            },
            "widgets_values": [
              "",
              "",
              "",
              "",
              "",
              ""
            ],
            "color": "#232",
            "bgcolor": "#353"
          },
          {
            "id": 76,
            "type": "OllamaConnectivityV2",
            "pos": [
              -2630,
              -910
            ],
            "size": [
              270,
              160
            ],
            "flags": {},
            "order": 0,
            "mode": 0,
            "inputs": [],
            "outputs": [
              {
                "localized_name": "connection",
                "name": "connection",
                "type": "OLLAMA_CONNECTIVITY",
                "links": [
                  131
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfyui-ollama",
              "ver": "2.1.0",
              "Node name for S&R": "OllamaConnectivityV2",
              "ue_properties": {
                "widget_ue_connectable": {},
                "input_ue_unconnectable": {},
                "version": "7.3"
              }
            },
            "widgets_values": [
              "http://127.0.0.1:8080",
              "gemma3:4b",
              0,
              "minutes",
              null
            ],
            "color": "#232",
            "bgcolor": "#353"
          },
          {
            "id": 78,
            "type": "OllamaOptionsV2",
            "pos": [
              -2330,
              -550
            ],
            "size": [
              286.103515625,
              754
            ],
            "flags": {
              "collapsed": true
            },
            "order": 1,
            "mode": 0,
            "inputs": [],
            "outputs": [
              {
                "localized_name": "options",
                "name": "options",
                "type": "OLLAMA_OPTIONS",
                "links": [
                  133
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfyui-ollama",
              "ver": "2.1.0",
              "Node name for S&R": "OllamaOptionsV2",
              "ue_properties": {
                "widget_ue_connectable": {},
                "input_ue_unconnectable": {},
                "version": "7.3"
              }
            },
            "widgets_values": [
              false,
              0,
              false,
              0.1,
              false,
              5,
              false,
              2048,
              false,
              64,
              false,
              1.1,
              false,
              0.8,
              false,
              368396900,
              "fixed",
              false,
              "",
              false,
              1,
              false,
              -1,
              false,
              40,
              false,
              0.9,
              false,
              0,
              false
            ],
            "color": "#232",
            "bgcolor": "#353"
          },
          {
            "id": 6,
            "type": "CLIPTextEncode",
            "pos": [
              -1900,
              -910
            ],
            "size": [
              422.84503173828125,
              164.31304931640625
            ],
            "flags": {
              "collapsed": true
            },
            "order": 2,
            "mode": 0,
            "inputs": [
              {
                "localized_name": "clip",
                "name": "clip",
                "type": "CLIP",
                "link": 273
              },
              {
                "localized_name": "text",
                "name": "text",
                "type": "STRING",
                "widget": {
                  "name": "text"
                },
                "link": 283
              }
            ],
            "outputs": [
              {
                "localized_name": "CONDITIONING",
                "name": "CONDITIONING",
                "type": "CONDITIONING",
                "slot_index": 0,
                "links": [
                  278
                ]
              }
            ],
            "title": "CLIP Text Encode (Positive Prompt)",
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.48",
              "Node name for S&R": "CLIPTextEncode",
              "ue_properties": {
                "version": "7.3",
                "widget_ue_connectable": {},
                "input_ue_unconnectable": {}
              },
              "enableTabs": false,
              "tabWidth": 65,
              "tabXOffset": 10,
              "hasSecondTab": false,
              "secondTabText": "Send Back",
              "secondTabOffset": 80,
              "secondTabWidth": 65
            },
            "widgets_values": [
              ""
            ],
            "color": "#232",
            "bgcolor": "#353"
          },
          {
            "id": 75,
            "type": "OllamaGenerateV2",
            "pos": [
              -2330,
              -910
            ],
            "size": [
              400,
              300
            ],
            "flags": {},
            "order": 4,
            "mode": 0,
            "inputs": [
              {
                "localized_name": "connectivity",
                "name": "connectivity",
                "shape": 7,
                "type": "OLLAMA_CONNECTIVITY",
                "link": 131
              },
              {
                "localized_name": "options",
                "name": "options",
                "shape": 7,
                "type": "OLLAMA_OPTIONS",
                "link": 133
              },
              {
                "localized_name": "images",
                "name": "images",
                "shape": 7,
                "type": "IMAGE",
                "link": 284
              },
              {
                "localized_name": "context",
                "name": "context",
                "shape": 7,
                "type": "OLLAMA_CONTEXT",
                "link": null
              },
              {
                "localized_name": "meta",
                "name": "meta",
                "shape": 7,
                "type": "OLLAMA_META",
                "link": null
              },
              {
                "localized_name": "prompt",
                "name": "prompt",
                "type": "STRING",
                "widget": {
                  "name": "prompt"
                },
                "link": 132
              }
            ],
            "outputs": [
              {
                "localized_name": "result",
                "name": "result",
                "type": "STRING",
                "links": [
                  146,
                  283
                ]
              },
              {
                "localized_name": "thinking",
                "name": "thinking",
                "type": "STRING",
                "links": null
              },
              {
                "localized_name": "context",
                "name": "context",
                "type": "OLLAMA_CONTEXT",
                "links": null
              },
              {
                "localized_name": "meta",
                "name": "meta",
                "type": "OLLAMA_META",
                "links": null
              }
            ],
            "properties": {
              "cnr_id": "comfyui-ollama",
              "ver": "2.1.0",
              "Node name for S&R": "OllamaGenerateV2",
              "ue_properties": {
                "widget_ue_connectable": {},
                "input_ue_unconnectable": {},
                "version": "7.3"
              }
            },
            "widgets_values": [
              "You are a professional AI Image Generation Prompt Engineer. Your core task is to receive a simple subject from a user and expand it into a structured, detailed, and creative JSON object. This JSON object will serve as an advanced prompt to guide AI image generation models (such as Midjourney, Stable Diffusion) in creating images with depth, atmosphere, and artistic quality.\n\nYou must strictly adhere to the JSON structure defined below and have a deep understanding of the meaning of each field to ensure the accuracy and high quality of the generated content.\n\n### JSON Structure Definition and Field Descriptions\n\nThe JSON you generate must contain the following nine keys:\n\n**\"subject\"**:\n*   **Meaning**: This is the core focus of the image. You need to describe the appearance, clothing, posture, action, expression, and gaze direction of this central character in detail.\n*   **Key Points**: Detail is crucial. For example, not just \"a woman,\" but \"a woman with short black hair\"; not just \"holding a hat,\" but \"holding a straw hat in her hand.\"\n\n**\"foreground\"**:\n*   **Meaning**: Describe the elements closest to the viewer or the \"camera.\" These elements are in front of or below the subject, adding layers and depth to the image.\n*   **Key Points**: Think about what would be in the immediate foreground if this were a photograph. For example: details on the ground (wet rocks, green grass), the corner of a table, falling petals, etc.\n\n**\"midground\"**:\n*   **Meaning**: Describe the plane where the subject is located and the objects that are on the same spatial level as the subject. This is the main area of the scene.\n*   **Key Points**: Clearly define the specific environment the subject is in. For example: the subject is standing on a rocky coast, a calm water surface, distant pier pilings, etc.\n\n**\"background\"**:\n*   **Meaning**: Describe the furthest elements in the scene, providing a grand environment and a sense of backstory.\n*   **Key Points**: Depict the distant scenery. For example: a distant city skyline, hazy mountains, the sky, the depths of a forest, etc.\n\n**\"composition\"**:\n*   **Meaning**: Use professional photography and art terms to describe the layout and structure of the image. This determines how the elements are organized.\n*   **Key Points**: Use standard composition rules. For example: rule of thirds, centered subject, symmetry, golden ratio, leading lines, vertical/horizontal orientation, depth layering, low/high angle shot, etc.\n\n**\"visual_guidance\"**:\n*   **Meaning**: Going a step further than composition, this describes how to guide the viewer's eye through the image and how to emphasize the focal point using visual elements.\n*   **Key Points**: Think about where the viewer's eyes will land first and where they will travel next. For example: using the lines of rocks to lead to the subject, the light and shadow contrast on the skin and clothing, the direction of the subject's gaze, the silhouette effect of the subject in the water, etc.\n\n**\"color_tone\"**:\n*   **Meaning**: Define the overall color scheme and feel of the image. Color is a powerful tool for conveying emotion.\n*   **Key Points**: Use descriptive words. For example: soft pastel tones, muted earthy palette, vibrant cyberpunk neon, monochromatic, high saturation, warm tones, etc. You can also add accent colors, such as \"an isolated warm orange rooftop as an accent.\"\n\n**\"lighting_mood\"**:\n*   **Meaning**: Describe the type, direction, and intensity of the light source, and the overall mood and atmosphere it creates.\n*   **Key Points**: Light is the soul of the scene. For example: soft natural lighting, golden hour, diffused daylight, dramatic Rembrandt lighting, mysterious moonlight, serene atmosphere, subtle backlight rim glow, etc.\n\n**\"caption\"**:\n*   **Meaning**: Fuse all the key elements above into a single, coherent, vivid, and narrative-driven sentence. This sentence itself is an excellent, ready-to-use image generation prompt.\n*   **Key Points**: This is not a simple string of keywords, but a complete, grammatically correct description of the scene. It should read like a textual summary of a painting, organically weaving all the details together.\n\n### Workflow\n\n1.  Wait for the user to provide a simple subject, for example, \"an astronaut on a strange planet.\"\n2.  Based on this subject, construct a complete, story-rich scene in your \"imagination.\"\n3.  Systematically fill in the details of your envisioned scene into each field of the JSON object, according to the definitions above.\n4.  Ensure that the content of all fields is coordinated and logically consistent. For example, if the composition is a close-up shot, the prompt should not mention the subject's feet. Maintain basic compositional logic to avoid contradictions.\n5.  Finally, distill all the information into the single, elegant long sentence in the \"caption\" field.\n\nOutput the complete JSON object.",
              "",
              false,
              false,
              "json"
            ],
            "color": "#232",
            "bgcolor": "#353"
          }
        ],
        "groups": [],
        "links": [
          {
            "id": 131,
            "origin_id": 76,
            "origin_slot": 0,
            "target_id": 75,
            "target_slot": 0,
            "type": "OLLAMA_CONNECTIVITY"
          },
          {
            "id": 133,
            "origin_id": 78,
            "origin_slot": 0,
            "target_id": 75,
            "target_slot": 1,
            "type": "OLLAMA_OPTIONS"
          },
          {
            "id": 146,
            "origin_id": 75,
            "origin_slot": 0,
            "target_id": 87,
            "target_slot": 0,
            "type": "STRING"
          },
          {
            "id": 132,
            "origin_id": -10,
            "origin_slot": 0,
            "target_id": 75,
            "target_slot": 5,
            "type": "STRING"
          },
          {
            "id": 274,
            "origin_id": -10,
            "origin_slot": 1,
            "target_id": 7,
            "target_slot": 0,
            "type": "CLIP"
          },
          {
            "id": 273,
            "origin_id": -10,
            "origin_slot": 1,
            "target_id": 6,
            "target_slot": 0,
            "type": "CLIP"
          },
          {
            "id": 279,
            "origin_id": 7,
            "origin_slot": 0,
            "target_id": -20,
            "target_slot": 0,
            "type": "CONDITIONING"
          },
          {
            "id": 278,
            "origin_id": 6,
            "origin_slot": 0,
            "target_id": -20,
            "target_slot": 1,
            "type": "CONDITIONING"
          },
          {
            "id": 147,
            "origin_id": 87,
            "origin_slot": 0,
            "target_id": -20,
            "target_slot": 2,
            "type": "*"
          },
          {
            "id": 283,
            "origin_id": 75,
            "origin_slot": 0,
            "target_id": 6,
            "target_slot": 1,
            "type": "STRING"
          },
          {
            "id": 284,
            "origin_id": -10,
            "origin_slot": 2,
            "target_id": 75,
            "target_slot": 2,
            "type": "IMAGE"
          }
        ],
        "extra": {
          "ue_links": [],
          "links_added_by_ue": []
        }
      }
    ]
  },
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7972024500000066,
      "offset": [
        1113.8338836046398,
        -294.187966958479
      ]
    },
    "frontendVersion": "1.28.7",
    "ue_links": [],
    "links_added_by_ue": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}