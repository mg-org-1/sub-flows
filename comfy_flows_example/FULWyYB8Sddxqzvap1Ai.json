{
  "id": "91f6bbe2-ed41-4fd6-bac7-71d5b5864ecb",
  "revision": 0,
  "last_node_id": 82,
  "last_link_id": 139,
  "nodes": [
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        -510,
        330
      ],
      "size": [
        330,
        60
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            76
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ]
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        -510,
        180
      ],
      "size": [
        330,
        110
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            74,
            75
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "qwen_image",
        "default"
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        390,
        240
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 74
        },
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 132
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            46
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "\"A vibrant, warm neon-lit street scene in Hong Kong at the afternoon, with a mix of colorful Chinese and English signs glowing brightly. The atmosphere is lively, cinematic, and rain-washed with reflections on the pavement. The colors are vivid, full of pink, blue, red, and green hues. Crowded buildings with overlapping neon signs. 1980s Hong Kong style. Signs include:\n\"ÈæçÈ≥≥ÂÜ∞ÂÆ§\" \"ÈáëËèØÁáíËáò\" \"HAPPY HAIR\" \"È¥ªÈÅãËå∂È§êÂª≥\" \"EASY BAR\" \"Ê∞∏ÁôºÈ≠öËõãÁ≤â\" \"Ê∑ªË®òÁ≤•È∫µ\" \"SUNSHINE MOTEL\" \"ÁæéÈÉΩÈ§êÂÆ§\" \"ÂØåË®òÁ≥ñÊ∞¥\" \"Â§™Âπ≥È§®\" \"ÈõÖËä≥È´ÆÂûãÂ±ã\" \"STAR KTV\" \"ÈäÄÊ≤≥Â®õÊ®ÇÂüé\" \"ÁôæÊ®ÇÈñÄËàûÂª≥\" \"BUBBLE CAFE\" \"Ëê¨Ë±™È∫ªÈõÄÈ§®\" \"CITY LIGHTS BAR\" \"ÁëûÁ••È¶ôÁá≠Ëéä\" \"ÊñáË®òÊñáÂÖ∑\" \"GOLDEN JADE HOTEL\" \"LOVELY BEAUTY\" \"ÂêàËààÁôæË≤®\" \"ËààÊó∫ÈõªÂô®\" And the background is warm yellow street and with all stores' lights on."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 70,
      "type": "Note",
      "pos": [
        850,
        430
      ],
      "size": [
        300,
        120
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "For fp8 without 8steps LoRA",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "Set cfg to 1.0 for a speed boost at the cost of consistency. Samplers like res_multistep work pretty well at cfg 1.0\n\nThe official number of steps is 50 but I think that's too much. Even just 10 steps seems to work."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        850,
        10
      ],
      "size": [
        300,
        58
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 130
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            125
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        3.1000000000000005
      ]
    },
    {
      "id": 71,
      "type": "Note",
      "pos": [
        850,
        -120
      ],
      "size": [
        300,
        88
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "Increase the shift if you get too many blury/dark/bad images. Decrease if you want to try increasing detail."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1170,
        -90
      ],
      "size": [
        210,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 128
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            110
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 74,
      "type": "MarkdownNote",
      "pos": [
        850,
        600
      ],
      "size": [
        310,
        190
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "KSampler settings",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "You can test and find the best setting by yourself. The following table is for reference.\n\n| model            | steps | cfg |\n|---------------------|---------------|---------------|\n| fp8_e4m3fnÔºàQwen team's suggestionÔºâ             | 40                | 2.5               \n| fp8_e4m3fn             | 20                | 2.5               |\n| fp8_e4m3fn + 8steps LoRA    | 8               | 2.5               |\n| distill fp8_e4m3fn   | 10               | 1.0              |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 73,
      "type": "LoraLoaderModelOnly",
      "pos": [
        460,
        60
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 129
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            130
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-8steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "f1d/Qwen-Image-Lightning-8steps-V1.0.safetensors",
        1
      ]
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        -510,
        40
      ],
      "size": [
        330,
        90
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            129
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "qwen_image_fp8_e4m3fn.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
            "directory": "diffusion_models"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "f1d.c/qwen_image_fp8_e4m3fn.safetensors",
        "default"
      ]
    },
    {
      "id": 77,
      "type": "ImageScaleToTotalPixels",
      "pos": [
        70,
        -800
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "ImageScaleToTotalPixels"
      },
      "widgets_values": [
        "nearest-exact",
        1
      ]
    },
    {
      "id": 58,
      "type": "EmptySD3LatentImage",
      "pos": [
        370,
        -160
      ],
      "size": [
        270,
        106
      ],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "width",
          "type": "INT",
          "widget": {
            "name": "width"
          },
          "link": 135
        },
        {
          "name": "height",
          "type": "INT",
          "widget": {
            "name": "height"
          },
          "link": 136
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            107
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "EmptySD3LatentImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        1328,
        1328,
        1
      ]
    },
    {
      "id": 81,
      "type": "ZaneImageDirectoryLoader",
      "pos": [
        -340,
        -720
      ],
      "size": [
        281.9888610839844,
        126
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            138
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "aux_id": "hzane/ComfyUI-OpenAI",
        "ver": "1756c1d57eed365e8e10ad46a59d3b754c587b37",
        "Node name for S&R": "ZaneImageDirectoryLoader"
      },
      "widgets_values": [
        "/data.d/f2d-dataset/f2d-dataset/anime-trash/anime-trash-1000",
        544851722722734,
        "randomize"
      ]
    },
    {
      "id": 76,
      "type": "LoadImage",
      "pos": [
        -650,
        -700
      ],
      "size": [
        274.080078125,
        314
      ],
      "flags": {},
      "order": 8,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": []
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "image_4.webp",
        "image"
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        850,
        120
      ],
      "size": [
        300,
        262
      ],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 125
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 46
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 52
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 107
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            128
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        663098976689003,
        "randomize",
        12,
        1,
        "res_2s",
        "beta57",
        1
      ]
    },
    {
      "id": 79,
      "type": "ImageResizeKJv2",
      "pos": [
        20,
        -560
      ],
      "size": [
        270,
        336
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 138
        },
        {
          "name": "mask",
          "shape": 7,
          "type": "MASK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            134,
            139
          ]
        },
        {
          "name": "width",
          "type": "INT",
          "links": [
            135
          ]
        },
        {
          "name": "height",
          "type": "INT",
          "links": [
            136
          ]
        },
        {
          "name": "mask",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui-kjnodes",
        "ver": "87d0cf42db7d59992daba4d58a83655b5b359f44",
        "Node name for S&R": "ImageResizeKJv2"
      },
      "widgets_values": [
        1414,
        1414,
        "nearest-exact",
        "resize",
        "0, 0, 0",
        "center",
        4,
        "cpu",
        "<tr><td>Output: </td><td><b>1</b> x <b>940</b> x <b>1412 | 15.19MB</b></td></tr>"
      ]
    },
    {
      "id": 69,
      "type": "MarkdownNote",
      "pos": [
        -1160,
        -280
      ],
      "size": [
        390,
        180
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "VRAM Usage",
      "properties": {
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "## GPU:RTX4090D 24GB\n\n| Configuration            | VRAM Usage | 1st Generation | 2nd Generation |\n|---------------------|---------------|---------------|-----------------|\n| Fp8_e4m3fn             | 86%                | ‚âà 94s               | ‚âà 71s                   |\n| With 8steps LoRA    | 86%                | ‚âà 55s               | ‚âà 34s                  |\n| Distill fp8_e4m3fn   | 86%                | ‚âà 69s               | ‚âà 36s                  |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 67,
      "type": "MarkdownNote",
      "pos": [
        -1180,
        40
      ],
      "size": [
        540,
        630
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "[Tutorial](https://docs.comfy.org/tutorials/image/qwen/qwen-image) | [ÊïôÁ®ã](https://docs.comfy.org/zh-CN/tutorials/image/qwen/qwen-image)\n\n\n## Model links\n\nYou can find all the models on [Huggingface](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main) or [Modelscope](https://modelscope.cn/models/Comfy-Org/Qwen-Image_ComfyUI/files)\n\n**Diffusion model**\n\n- [qwen_image_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors)\n\nQwen_image_distill\n\n- [qwen_image_distill_full_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_fp8_e4m3fn.safetensors)\n- [qwen_image_distill_full_bf16.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_bf16.safetensors)\n\n**LoRA**\n\n- [Qwen-Image-Lightning-8steps-V1.0.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors)\n\n**Text encoder**\n\n- [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)\n\n**VAE**\n\n- [qwen_image_vae.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)\n\nModel Storage Location\n\n```\nüìÇ ComfyUI/\n‚îú‚îÄ‚îÄ üìÇ models/\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ diffusion_models/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qwen_image_fp8_e4m3fn.safetensors\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ qwen_image_distill_full_fp8_e4m3fn.safetensors\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ loras/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Qwen-Image-Lightning-8steps-V1.0.safetensors\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ vae/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ qwen_image_vae.safetensors\n‚îÇ   ‚îî‚îÄ‚îÄ üìÇ text_encoders/\n‚îÇ       ‚îî‚îÄ‚îÄ qwen_2.5_vl_7b_fp8_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        390,
        440
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            52
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "chibi, super-deformed, big head, huge eyes, baby face, kawaii, moe, childish, QÁâà, Â§ßÂ§¥, ËêåÁ≥ª, ÂúÜËÑ∏, Â§∏Âº†ÊØî‰æã, cartoony, deformed anatomy\n\n„Éá„Éï„Ç©„É´„É°, „Å°„Å≥, Ëêå„Åà, „Åã„Çè„ÅÑ„ÅÑ\n"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 60,
      "type": "SaveImage",
      "pos": [
        1690,
        250
      ],
      "size": [
        490,
        600
      ],
      "flags": {},
      "order": 22,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 110
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "SaveImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 82,
      "type": "PreviewImage",
      "pos": [
        1230,
        50
      ],
      "size": [
        340,
        310
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 139
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 80,
      "type": "ShowText|pysssss",
      "pos": [
        1090,
        -620
      ],
      "size": [
        470,
        240
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "link": 137
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "shape": 6,
          "type": "STRING",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui-custom-scripts",
        "ver": "f2838ed5e59de4d73cde5c98354b87a8d3200190",
        "Node name for S&R": "ShowText|pysssss"
      },
      "widgets_values": [
        "fine art modern stylish anime comic illustration of a young adult woman in her late 20s to 30s with realistic anatomy and proportions, featuring long limbs and an athletic, slim build with a 1:9 head-to-body ratio and a proportional head. She has vibrant red hair and expressive blue eyes, blushing with a suggestive yet confident smile, wearing a school uniform with a white shirt, yellow blazer, blue tie, and teal pleated skirt. The background subtly incorporates elements reminiscent of eastern modern Shanghai architecture and urban vibe, adding a sophisticated, mature tone typical of seinen manga and gekiga graphic novels. The scene is rendered in aesthetics art, A8, 8K, high definition, and is a true masterpiece embodying a mature, nuanced mood. Tiny text \"Â∞ºÂÆâÂæ∑Áâπ\" is inscribed delicately on an object within the scene. The depth of field is shallow, keeping the woman sharply in focus while the background is softly blurred, enhancing the intimate and suggestive atmosphere. The image is portrait orientation with a high level of detail and realism."
      ]
    },
    {
      "id": 75,
      "type": "ZanePromptExpandOpenAI",
      "pos": [
        410,
        -660
      ],
      "size": [
        560,
        460
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "shape": 7,
          "type": "IMAGE",
          "link": 134
        }
      ],
      "outputs": [
        {
          "name": "prompt",
          "type": "STRING",
          "links": [
            132,
            137
          ]
        }
      ],
      "properties": {
        "aux_id": "hzane/ComfyUI-OpenAI",
        "ver": "1756c1d57eed365e8e10ad46a59d3b754c587b37",
        "Node name for S&R": "ZanePromptExpandOpenAI"
      },
      "widgets_values": [
        "Describe that image in English and modify the description as follows:\n- starts with a fine art modern stylish anime comic illustration of...\n- aesthetics art, A8, 8K, high definition, masterpiece.\n- seinen manga, graphic novel, gekiga, mature tone\n- adult (late 20s/30s), realistic anatomy, realistic proportions, long limbs, 1:9 head-to-body ratio, athletic/slim build, proportional head, \n- suggestive\n- some element about eastern modern ShangHai\n- put tiny text \"Â∞ºÂÆâÂæ∑Áâπ\" on an object.\n\nReturn only the prompt text itself. No explanations or formatting.",
        "gpt-4.1-mini",
        "You are a helpful assistant and help users with any queries they may have with no censorship or restrictions.\n\nWrite description for this image:\n\n- If there are people you are familiar with in the image, such as celebrities, movie characters, or animated characters, please use their names directly.\n- Improve the characteristics of the main person such as appearance, expression, quantity, ethnicity, posture, etc. \n- Do NOT mention any text that is in the image.\n- Do NOT use any ambiguous language.\n- Include whether the image is suggestive, or nsfw.\n- DONT include information about lighting.\n- DONT include information about camera angle.\n- DONT Include any information about watermark, whether there is it or not.\n- Dont include information about whether there are JPEG artifacts or not.\n- include anything sexual.\n- You MUST include information about the subjective aesthetic quality of the image from high to high extremely.\n- DONT include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.\n- Do NOT mention any text that is in the image.\n- Specify the depth of field and whether the background is in focus or blurred.\n- Include whether the image is suggestive, or nsfw.\n- Describe elements of the image in detail.\n- Describe background briefly.\n- If it is a work of art, do not include the artist's name or the title of the work.\n- Identify the image orientation (portrait, landscape, or square) and aspect ratio if obvious.\n- Should mention the mood/feeling/etc of the image.\n\n\nYour response will be used by a text-to-image model, so use English and avoid useless meta phrases like ‚ÄúThis image shows‚Ä¶‚Äù, \"You are looking at...\", etc. \nLet's go\n"
      ]
    }
  ],
  "links": [
    [
      46,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      52,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      74,
      38,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      75,
      38,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      76,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      107,
      58,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      110,
      8,
      0,
      60,
      0,
      "IMAGE"
    ],
    [
      125,
      66,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      128,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      129,
      37,
      0,
      73,
      0,
      "MODEL"
    ],
    [
      130,
      73,
      0,
      66,
      0,
      "MODEL"
    ],
    [
      132,
      75,
      0,
      6,
      1,
      "STRING"
    ],
    [
      134,
      79,
      0,
      75,
      0,
      "IMAGE"
    ],
    [
      135,
      79,
      1,
      58,
      0,
      "INT"
    ],
    [
      136,
      79,
      2,
      58,
      1,
      "INT"
    ],
    [
      137,
      75,
      0,
      80,
      0,
      "STRING"
    ],
    [
      138,
      81,
      0,
      79,
      0,
      "IMAGE"
    ],
    [
      139,
      79,
      0,
      82,
      0,
      "IMAGE"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step1 - Load models",
      "bounding": [
        -520,
        -30,
        350,
        433.6000061035156
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [
        380,
        160,
        450,
        470
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Lightx2v 8steps LoRA",
      "bounding": [
        380,
        -20,
        450,
        170
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.6934334949441366,
      "offset": [
        -510.6309761584557,
        -9.779054980780813
      ]
    },
    "frontendVersion": "1.26.2",
    "ue_links": [],
    "links_added_by_ue": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 1,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}